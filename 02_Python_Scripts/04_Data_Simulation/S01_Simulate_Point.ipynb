{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8e59b0-4ca7-4086-afdb-e168c3902214",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################################################\n",
    "# This script simulates data for point-prediction modeling.\n",
    "########################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27db9b4d-4978-4a0c-881e-60b23adfa3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################################################\n",
    "# Import packages\n",
    "########################################################################################################################\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from typing import Literal, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50fa71ce-0fcf-4768-ac88-cb71b3fc45db",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################################################\n",
    "# Define the core function to simulate the data\n",
    "########################################################################################################################\n",
    "def simulate_point(n_samples: int = 1000,\n",
    "                   n_features: int = 50,\n",
    "                   n_informative: int = 15,\n",
    "                   n_redundant: int = 5,\n",
    "                   n_binary_features: int = 5,\n",
    "                   prevalence: float = 0.2,\n",
    "                   missing_rate: float = 0.2,\n",
    "                   test_rate: float = 0.3,\n",
    "                   impute: Literal['Zero', 'Mean', 'Median'] = 'Zero',\n",
    "                   random_state: Optional[int] = 42):\n",
    "    \"\"\"\n",
    "    :param n_samples: Number of samples\n",
    "    :param n_features: Number of features\n",
    "    :param n_informative: Number of informative features\n",
    "    :param n_redundant: Number of redundant features\n",
    "    :param n_binary_features: Number of binary_features\n",
    "    :param prevalence: Prevalence rate in (0, 1)\n",
    "    :param missing_rate: Missing rate in (0, 1)\n",
    "    :param test_rate: Proportion of the held-out test set\n",
    "    :param impute: A string in ['Zero', 'Mean', 'Median'] representing the imputation method\n",
    "    :param random_state: Random state\n",
    "    :return:\n",
    "    (a) X_train_: np.ndarray. Feature dataset in the training partition\n",
    "    with shape (n_samples * (1 - test_rate), n_features * 2)\n",
    "    (b) X_test_: np.ndarray. Feature dataset in the training partition\n",
    "    with shape (n_samples * test_rate, n_features * 2)\n",
    "    (c) y_train_: np.ndarray. Target dataset in the training partition\n",
    "    with shape (n_samples * (1 - test_rate), )\n",
    "    (d) y_test_: np.ndarray. Target dataset in the training partition\n",
    "    with shape (n_samples * test_rate, )\n",
    "    (e) feat_names_: list of strings representing the names of the features.\n",
    "    Names containing 'C' represent continuous variables, and 'B' for binary variables.\n",
    "    Names containing '!NA' represent the binary missingness indicator variables.\n",
    "    \"\"\"\n",
    "\n",
    "    # Validation of inputs\n",
    "    assert 0 < prevalence < 1\n",
    "    assert 0 <= missing_rate < 1\n",
    "    assert n_informative + n_redundant <= n_features\n",
    "    assert n_binary_features <= n_features\n",
    "    assert 0 < test_rate < 1\n",
    "    assert impute in ['Zero', 'Mean', 'Median']\n",
    "\n",
    "    # Setting random state\n",
    "    rng = np.random.default_rng(random_state)\n",
    "\n",
    "    # Sklearn-based data simulation (continuous variables only)\n",
    "    X_, y_ = make_classification(n_samples=n_samples,\n",
    "                                 n_features=n_features,\n",
    "                                 n_informative=n_informative,\n",
    "                                 n_redundant=n_redundant,\n",
    "                                 n_repeated=0,\n",
    "                                 n_classes=2,\n",
    "                                 weights=[1 - prevalence, prevalence],\n",
    "                                 shuffle=False,\n",
    "                                 random_state=random_state)\n",
    "    X_ = X_.astype(np.float32)\n",
    "    y_ = y_.astype(np.int64)\n",
    "\n",
    "    # Creating feature names\n",
    "    feat_names_ = [f'X_{i+1}C' for i in range(n_features)]\n",
    "\n",
    "    # Converting some continuous features to binary features\n",
    "    if n_binary_features > 0:\n",
    "        binary_idx = rng.choice(n_features, size=n_binary_features, replace=False)\n",
    "        for j in binary_idx:\n",
    "            feat_names_[j] = f'X_{j+1}B'\n",
    "            thr = np.nanmedian(X_[:, j])\n",
    "            X_[:, j] = (X_[:, j] > thr).astype(np.float32)\n",
    "\n",
    "    # Simulating missingness\n",
    "    if missing_rate > 0:\n",
    "        mask = rng.random(X_.shape) < missing_rate\n",
    "        X_[mask] = np.nan\n",
    "    else:\n",
    "        mask = np.isnan(X_)\n",
    "\n",
    "    # Creating missingness indicator\n",
    "    M = mask.astype(np.float32)\n",
    "\n",
    "    # Imputing the data\n",
    "    if impute == 'Zero':\n",
    "        fill_values = np.zeros(n_features, dtype=np.float32)\n",
    "    elif impute == 'Mean':\n",
    "        fill_values = np.nanmean(X_, axis=0).astype(np.float32)\n",
    "    else:\n",
    "        fill_values = np.nanmedian(X_, axis=0).astype(np.float32)\n",
    "    fill_values = np.where(np.isnan(fill_values), 0.0, fill_values).astype(np.float32)\n",
    "    nan_idxs = np.where(np.isnan(X_))\n",
    "    X_[nan_idxs] = fill_values[nan_idxs[1]]\n",
    "\n",
    "    # Creating extra variable names for the binary missingness indicators\n",
    "    feat_names_ += [f'{c}!NA' for c in feat_names_]\n",
    "\n",
    "    # Concatenating the main data with the binary missingness indicators\n",
    "    X_ = np.concatenate([X_, M], axis=1).astype(np.float32)\n",
    "\n",
    "    # Stratified partitioning\n",
    "    X_train_, X_test_, y_train_, y_test_ = train_test_split(X_, y_, test_size=test_rate,\n",
    "                                                            random_state=random_state, stratify=y_,\n",
    "                                                            shuffle=True)\n",
    "    return X_train_, X_test_, y_train_, y_test_, feat_names_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6af75787-2875-4b97-83de-eb448be6bd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################################################\n",
    "# USER_SPECIFIC SETTING\n",
    "# OUT_DIR_PATH: Path of the output directory storing the organized datasets for modeling\n",
    "# N_SAMPLES: Number of samples\n",
    "# N_FEATURES: Number of features\n",
    "# N_INFORMATIVE: Number of informative features\n",
    "# N_REDUNDANT: Number of redundant features\n",
    "# N_BINARY_FEATURES: Number of binary_features\n",
    "# PREVALENCE: Prevalence rate in (0, 1)\n",
    "# MISSING_RATE: Missing rate in (0, 1)\n",
    "# TEST_RATE: Proportion of the held-out test set\n",
    "# IMPUTE: A string in ['Zero', 'Mean', 'Median'] representing the imputation method\n",
    "# RANDOM_STATE: Random state\n",
    "########################################################################################################################\n",
    "OUT_DIR_PATH: str = 'Point_Model_Data/1_encounters_60_days/'\n",
    "N_SAMPLES: int = 1000\n",
    "N_FEATURES: int = 50\n",
    "N_INFORMATIVE: int = 15\n",
    "N_REDUNDANT: int = 5\n",
    "N_BINARY_FEATURES: int = 5\n",
    "PREVALENCE: float = 0.2\n",
    "MISSING_RATE: float = 0.2\n",
    "TEST_RATE: float = 0.3\n",
    "IMPUTE: Literal['Zero', 'Mean', 'Median'] = 'Zero'\n",
    "RANDOM_STATE: Optional[int] = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c129f283-63b0-4ffc-b3f3-8f8f3bb62426",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################################################\n",
    "# Simulate the data\n",
    "########################################################################################################################\n",
    "X_train, X_test, y_train, y_test, feat_names = simulate_point(n_samples=N_SAMPLES,\n",
    "                                                              n_features=N_FEATURES,\n",
    "                                                              n_informative=N_INFORMATIVE,\n",
    "                                                              n_redundant=N_REDUNDANT,\n",
    "                                                              n_binary_features=N_BINARY_FEATURES,\n",
    "                                                              prevalence=PREVALENCE,\n",
    "                                                              missing_rate=MISSING_RATE,\n",
    "                                                              test_rate=TEST_RATE,\n",
    "                                                              impute=IMPUTE,\n",
    "                                                              random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf4b871-6b11-4bd2-a525-316376eb3ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################################################\n",
    "# Define the output paths and export the data\n",
    "########################################################################################################################\n",
    "out_dir_sub: str = os.path.join(OUT_DIR_PATH, f'{IMPUTE}/')\n",
    "os.makedirs(out_dir_sub, exist_ok=True)\n",
    "\n",
    "# Export X_train\n",
    "X_train_path: str = f'{out_dir_sub}X_train.npy'\n",
    "np.save(X_train_path, X_train)\n",
    "\n",
    "# Export X_test\n",
    "X_test_path: str = f'{out_dir_sub}X_test.npy'\n",
    "np.save(X_test_path, X_test)\n",
    "\n",
    "# Export y_train\n",
    "y_train_path: str = f'{out_dir_sub}y_train.npy'\n",
    "np.save(y_train_path, y_train)\n",
    "\n",
    "# Export y_test\n",
    "y_test_path: str = f'{out_dir_sub}y_test.npy'\n",
    "np.save(y_test_path, y_test)\n",
    "\n",
    "# Export feat_names\n",
    "feat_name_path: str = f'{out_dir_sub}Feature_Names.csv'\n",
    "pd.DataFrame({'Features': feat_names}).to_csv(feat_name_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
