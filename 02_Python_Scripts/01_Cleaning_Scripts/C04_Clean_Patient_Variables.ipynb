{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8af71d80-bcc3-41e9-ad79-87f80bef4469",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################################\n",
    "# Overview: This script cleans the extracted patient-level data mart.\n",
    "############################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7cedbe5-1e71-4b13-95f0-557c6f0dac48",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "########################################################################################################################\n",
    "# Import packages\n",
    "########################################################################################################################\n",
    "import datetime\n",
    "import gc\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import warnings\n",
    "from ast import literal_eval\n",
    "from itertools import zip_longest\n",
    "from pyarrow.parquet import ParquetFile\n",
    "warnings.filterwarnings('ignore', category=pd.errors.SettingWithCopyWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "613bc638-c5b5-43c8-b363-315092356500",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################################################\n",
    "# USER_SPECIFIC SETTING\n",
    "# DATA_IN_DIR_PATH: Path of the input directory of the patient-level dataset \n",
    "# (created in C01_Data_Transfer.ipynb)\n",
    "# DATA_OUT_DIR_PATH: Path of the output directory of the patient-level dataset \n",
    "# (created in C01_Data_Transfer.ipynb)\n",
    "# DICT_IN_FILE_PATH: Path of the input data dictionary file\n",
    "# (created in C03_Encode_Encounter_Variables.ipynb)\n",
    "# DICT_OUT_FILE_PATH: Path of the output data dictionary file\n",
    "########################################################################################################################\n",
    "DATA_IN_DIR_PATH: str = '../00_Data/00_Raw_Data/'\n",
    "DATA_OUT_DIR_PATH: str = '../00_Data/01_Cleaned_Data/'\n",
    "DICT_IN_FILE_PATH: str = '../00_Data/99_Dictionary/Dictionary_v2.xlsx'\n",
    "DICT_OUT_FILE_PATH: str = '../00_Data/99_Dictionary/Dictionary_v3.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd2c0d5-ec6a-4195-bb20-22c871047eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################################################\n",
    "# Load the data dictionary\n",
    "########################################################################################################################\n",
    "df_dict_pat: pd.DataFrame = pd.read_excel(DICT_IN_FILE_PATH, sheet_name='Patient')\n",
    "df_dict_enc: pd.DataFrame = pd.read_excel(DICT_IN_FILE_PATH, sheet_name='Encounter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938f35b6-084f-4dea-925b-17b4bf4567e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################################################\n",
    "# Load the header of the patient-level dataset\n",
    "########################################################################################################################\n",
    "pat_data_path: str = os.path.join(DATA_IN_DIR_PATH, 'Patient_full.parquet')\n",
    "pf: ParquetFile = ParquetFile(pat_data_path)\n",
    "first_row: pa.lib.RecordBatch = next(pf.iter_batches(batch_size=1))\n",
    "header: list[str] = pa.Table.from_batches([first_row]).to_pandas().columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70518311-1781-4304-8d7f-fd6ff557577b",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################################################\n",
    "# Initiate a single-column pandas.DataFrame containing the first column of the patient-level dataset\n",
    "# (i.e., the patient identifier column = PatientDurableKey)\n",
    "# Create an extra copy of df_dict_pat for modification\n",
    "########################################################################################################################\n",
    "df_out: pd.DataFrame = pd.DataFrame({header[0]: pd.read_parquet(pat_data_path, \n",
    "                                                                columns=[header[0]]).iloc[:, 0]})\n",
    "N: int = df_out.shape[0]    \n",
    "df_dict_pat_v2: pd.DataFrame = pd.DataFrame(None, columns=df_dict_pat.columns)\n",
    "df_dict_pat_v2.insert(2, 'Sampled_Percentage', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26c17b2-df05-4d8b-91ee-2b0a2b578eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################################################\n",
    "# Part A. Encode and extract data of date & continuous variables\n",
    "########################################################################################################################\n",
    "for row_idx, row in df_dict_pat[df_dict_pat['Variable_Type'].isin(['datetime.date',\n",
    "                                                                   'Date as float',\n",
    "                                                                   'Continuous'])].iterrows():\n",
    "    var_name: str = row['Variable_Name']\n",
    "    var_type: str = row['Variable_Type']\n",
    "    remark: str = row['Remark']\n",
    "    log_head: str = f'[{row_idx}] {var_name} '\n",
    "\n",
    "    ####################################################################################################################\n",
    "    # A1. Load the uncleared single-column data\n",
    "    ####################################################################################################################\n",
    "    df_cur: pd.DataFrame = pd.read_parquet(pat_data_path, columns=[var_name])\n",
    "\n",
    "    ####################################################################################################################\n",
    "    # A2. Extract data\n",
    "    ####################################################################################################################\n",
    "    # Case 1. Date variables in datetime.date format\n",
    "    if var_type == 'datetime.date':\n",
    "        print(f'{log_head}datetime.date --> Date')\n",
    "        df_cur[var_name] = pd.to_datetime(df_cur[var_name])\n",
    "        new_var_type: str = 'Date'\n",
    "\n",
    "    # Case 2. Date variables in float format\n",
    "    elif var_type == 'Date as float':\n",
    "        print(f'{log_head}Date as float --> Date')\n",
    "        df_cur[var_name] = df_cur[var_name].apply(lambda x: str(int(x)) if pd.notna(x) else None)\n",
    "        df_cur[var_name] = pd.to_datetime(df_cur[var_name], format='%Y%m%d', errors='coerce')\n",
    "        new_var_type: str = 'Date'\n",
    "\n",
    "    # Case 3. Continuous variables\n",
    "    else:\n",
    "        print(f'{log_head}Continuous (as is)')\n",
    "        new_var_type: str = 'Continuous'\n",
    "\n",
    "    df_out[var_name] = df_cur[var_name]\n",
    "\n",
    "    ########################################################################################################################\n",
    "    # A3. Update dictionary\n",
    "    ########################################################################################################################\n",
    "    sampled_ratio: int = int(round(df_cur[var_name].notna().sum() / N, 2) * 100)\n",
    "    record_cur: pd.DataFrame = pd.DataFrame({'Variable_Name': [var_name],\n",
    "                                             'Sample_Size': int(df_cur[var_name].notna().sum()),\n",
    "                                             'Sampled_Percentage': [sampled_ratio],\n",
    "                                             'Encoded_Values': [np.nan],\n",
    "                                             'Variable_Type': [new_var_type],\n",
    "                                             'Remark': [remark]})\n",
    "    df_dict_pat_v2 = pd.concat([df_dict_pat_v2, record_cur], ignore_index=True)\n",
    "    del df_cur\n",
    "    gc.collect() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b49021-a1eb-4192-9aee-8a9d3bcead9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################################################\n",
    "# Part B. Encode race data (from 5 variables) into a single nominal variable\n",
    "########################################################################################################################\n",
    "# Initialize a list to store race data\n",
    "race_records: list[list[int]] = []\n",
    "\n",
    "########################################################################################################################\n",
    "# B1. Load the uncleaned 5-column data\n",
    "########################################################################################################################\n",
    "race_vars: list[str] = ['FirstRace', 'SecondRace', 'ThirdRace', 'FourthRace', 'FifthRace']\n",
    "df_cur: pd.DataFrame = pd.read_parquet(pat_data_path, columns=race_vars)\n",
    "\n",
    "########################################################################################################################\n",
    "# B2. Load and apply the encoding scheme to each race column, then concatenate\n",
    "########################################################################################################################\n",
    "race_encoder: dict[str, int] = literal_eval(\n",
    "    df_dict_pat.loc[df_dict_pat['Variable_Name'] == 'FirstRace',\n",
    "                    'Encoded_Values'].values[0]\n",
    ")\n",
    "\n",
    "for var in race_vars:\n",
    "    df_cur[var] = df_cur[var].replace(race_encoder)\n",
    "    race_records.append(df_cur[var].values)\n",
    "\n",
    "########################################################################################################################\n",
    "# B3. Transform race_records\n",
    "########################################################################################################################\n",
    "race_records = [row.tolist() for row in np.array(race_records).T]\n",
    "race_records_new: list[int] = []\n",
    "\n",
    "for race_record in race_records:\n",
    "    unique_races: np.array = np.unique(np.array(race_record)[~np.isnan(race_record)])\n",
    "    if len(unique_races) == 1:              # Take the unique race\n",
    "        race_records_new.append(unique_races[0])\n",
    "    elif len(unique_races) > 1:              # Report multiple races\n",
    "        race_records_new.append(6)\n",
    "    else:                                    # Didn't report\n",
    "        race_records_new.append(np.nan)\n",
    "\n",
    "########################################################################################################################\n",
    "# B4. Obtain the decoder from the encoder\n",
    "########################################################################################################################\n",
    "race_decoder: dict[int, str] = {v: k for k, v in race_encoder.items() if k != ''} | {6: 'Multiple Races'}\n",
    "\n",
    "########################################################################################################################\n",
    "# B5. Use race_records_new to perform one-hot encoding and concatenate to df_out, and update the data dictionary\n",
    "########################################################################################################################\n",
    "df_race: pd.DataFrame = pd.DataFrame({'Race': race_records_new})\n",
    "assert set(df_race['Race'].dropna().unique()) == set(range(7))\n",
    "\n",
    "for race_code, race_desc in race_decoder.items():\n",
    "    new_var_name: str = f'Race{race_code}_{race_desc}'\n",
    "    df_out[new_var_name] = df_race['Race'].apply(lambda x: np.nan if pd.isna(x) else int(x == race_code)).astype('Int32')\n",
    "    sample_size: int = df_out[new_var_name].notna().sum()\n",
    "    sampled_ratio: int = int(round(sample_size / N, 2) * 100)\n",
    "\n",
    "    record_cur: pd.DataFrame = pd.DataFrame({\n",
    "        'Variable_Name': [new_var_name],\n",
    "        'Sample_Size': [sample_size],\n",
    "        'Sampled_Percentage': [sampled_ratio],\n",
    "        'Encoded_Values': [{0: 'No', 1: 'Yes'}],\n",
    "        'Variable_Type': ['Binary'],\n",
    "        'Remark': [np.nan]\n",
    "    })\n",
    "\n",
    "    df_dict_pat_v2 = pd.concat([df_dict_pat_v2, record_cur], ignore_index=True)\n",
    "\n",
    "del race_records\n",
    "del race_records_new\n",
    "del df_race\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241851e2-1857-43f3-a7d5-cfa0f9b5d14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################################################\n",
    "# Part C. Encode all other variables (binary / nominal / ordinal)\n",
    "########################################################################################################################\n",
    "df_dict_pat_sub: pd.DataFrame = df_dict_pat[df_dict_pat['Variable_Type'].isin(['Nominal', 'Binary', 'Ordinal'])]\n",
    "df_dict_pat_sub = df_dict_pat_sub[df_dict_pat_sub['Variable_Name'].apply(lambda x: not x.endswith('Race'))]\n",
    "df_out_cat: pd.DataFrame = pd.DataFrame(None)       # Create empty pandas.DataFrame for the data and dictionary of\n",
    "df_dict_pat_cat: pd.DataFrame = pd.DataFrame(None)  # the categorical variables\n",
    "\n",
    "for row_idx, row in df_dict_pat_sub.iterrows():\n",
    "    var_name: str = row['Variable_Name']\n",
    "    var_type: str = row['Variable_Type']\n",
    "    encoder: dict[str, int] = literal_eval(row['Encoded_Values'])\n",
    "    remark: str = row['Remark']\n",
    "    log_head: str = f'[{row_idx}. {var_name}]'\n",
    "\n",
    "    ####################################################################################################################\n",
    "    # C1. Load the uncleaned single-column data\n",
    "    ####################################################################################################################\n",
    "    df_cur: pd.DataFrame = pd.read_parquet(pat_data_path, columns=[var_name])\n",
    "\n",
    "    ####################################################################################################################\n",
    "    # C2. Identify the codes for missingness\n",
    "    ####################################################################################################################\n",
    "    missing_encoder: dict[str, int] = {k: v for k, v in encoder.items() if v is not None and v < 0}\n",
    "    non_missing_encoder: dict[str, int] = {k: v for k, v in encoder.items() if v is not None and v >= 0}\n",
    "    missing_decoder: dict[int, str] = {v: k for k, v in missing_encoder.items()}\n",
    "    non_missing_decoder: dict[int, str] = {v: k for k, v in non_missing_encoder.items()}\n",
    "\n",
    "    ####################################################################################################################\n",
    "    # C3. Apply the encoder to the data\n",
    "    ####################################################################################################################\n",
    "    df_cur[var_name].replace(encoder, inplace=True)\n",
    "\n",
    "    ########################################################################################################################\n",
    "    # C4. Handle non-ordinal variables first\n",
    "    ########################################################################################################################\n",
    "    if var_type in ['Binary', 'Nominal']:\n",
    "    \n",
    "        if var_type == 'Binary':\n",
    "            assert len(non_missing_encoder) == 2\n",
    "            assert set(non_missing_encoder.values()) == {0, 1}, non_missing_encoder.values()\n",
    "        else:\n",
    "            assert len(non_missing_encoder) > 2\n",
    "    \n",
    "        ####################################################################################################################\n",
    "        # 4.1 Encode only the positive value for binary variables, and all values for nominal variables\n",
    "        ####################################################################################################################\n",
    "        for k, v in non_missing_decoder.items():\n",
    "    \n",
    "            if var_type == 'Binary' and k == 0:\n",
    "                continue\n",
    "    \n",
    "            new_var_name: str = f'{var_name}_{k}={v}'\n",
    "            df_out_cat[new_var_name] = df_cur[var_name].apply(\n",
    "                lambda x: np.nan if pd.isna(x) or x < 0 else int(x == k)\n",
    "            ).astype('Int32')  # Cleaned data\n",
    "    \n",
    "            sample_size: int = df_out_cat[new_var_name].notna().sum()\n",
    "            sampled_ratio: int = int(round(sample_size / N, 2) * 100)\n",
    "    \n",
    "            record_cur: pd.DataFrame = pd.DataFrame({\n",
    "                'Variable_Name': [new_var_name],\n",
    "                'Sample_Size': [sample_size],\n",
    "                'Sampled_Percentage': [sampled_ratio],\n",
    "                'Encoded_Values': [{0: 'No', 1: 'Yes'}],\n",
    "                'Variable_Type': ['Binary'],\n",
    "                'Remark': [remark]\n",
    "            })\n",
    "    \n",
    "            df_dict_pat_cat = pd.concat([df_dict_pat_cat, record_cur], ignore_index=True)  # Cleaned dictionary\n",
    "    \n",
    "    ########################################################################################################################\n",
    "    # C5. Handle nominal encoding\n",
    "    ########################################################################################################################\n",
    "    else:\n",
    "        assert len(non_missing_encoder) > 2\n",
    "    \n",
    "        ####################################################################################################################\n",
    "        # 5.1 Encode only the non-negative values\n",
    "        ####################################################################################################################\n",
    "        df_out_cat[var_name] = df_cur[var_name].apply(\n",
    "            lambda x: np.nan if pd.isna(x) or x < 0 else x\n",
    "        ).astype('Int32')\n",
    "    \n",
    "        sample_size: int = df_out_cat[var_name].notna().sum()\n",
    "        sampled_ratio: int = int(round(sample_size / N, 2) * 100)\n",
    "    \n",
    "        record_cur: pd.DataFrame = pd.DataFrame({\n",
    "            'Variable_Name': [var_name],\n",
    "            'Sample_Size': [sample_size],\n",
    "            'Sampled_Percentage': [sampled_ratio],\n",
    "            'Encoded_Values': [non_missing_decoder],\n",
    "            'Variable_Type': ['Ordinal'],\n",
    "            'Remark': [remark]\n",
    "        })\n",
    "    \n",
    "        df_dict_pat_cat = pd.concat([df_dict_pat_cat, record_cur], ignore_index=True)  # Cleaned dictionary\n",
    "\n",
    "    ########################################################################################################################\n",
    "    # C6. Handling the encoding of the missing values\n",
    "    # All missing values in these newly created columns will be filled as 0 to represent structural missingness\n",
    "    ########################################################################################################################\n",
    "    for k, v in missing_decoder.items():\n",
    "        new_var_name: str = f'{var_name}_{k}={v}'\n",
    "        df_out_cat[new_var_name] = df_cur[var_name].apply(\n",
    "            lambda x: np.nan if pd.isna(x) else int(x == k)\n",
    "        ).astype('Int32')\n",
    "    \n",
    "        sample_size: int = df_out_cat[new_var_name].notna().sum()\n",
    "        sampled_ratio: int = int(round(sample_size / N, 2) * 100)\n",
    "    \n",
    "        record_cur: pd.DataFrame = pd.DataFrame({\n",
    "            'Variable_Name': [new_var_name],\n",
    "            'Sample_Size': [sample_size],\n",
    "            'Sampled_Percentage': [sampled_ratio],\n",
    "            'Encoded_Values': [{0: 'No', 1: 'Yes'}],\n",
    "            'Variable_Type': ['Binary'],\n",
    "            'Remark': [remark]\n",
    "        })\n",
    "    \n",
    "        df_dict_pat_cat = pd.concat([df_dict_pat_cat, record_cur], ignore_index=True)  # Cleaned dictionary\n",
    "    \n",
    "    del df_cur\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e21f69-b930-4e60-a419-0dd7ec1b95ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################################################\n",
    "# Part D. Concatenate the data sets and dictionaries respectively, and save them\n",
    "########################################################################################################################\n",
    "df_out = pd.concat([df_out, df_out_cat], axis=1)\n",
    "df_dict_pat_v2 = pd.concat([df_dict_pat_v2, df_dict_pat_cat], axis=0)\n",
    "\n",
    "os.makedirs(DATA_OUT_DIR_PATH, exist_ok=True)\n",
    "data_file_path: str = os.path.join(DATA_OUT_DIR_PATH, 'Patient_full_v1.parquet')\n",
    "df_out.to_parquet(data_file_path)\n",
    "print(f'Cleaned data (v1) saved with dimension={df_out.shape}')\n",
    "\n",
    "with pd.ExcelWriter(DICT_OUT_FILE_PATH) as writer:\n",
    "    df_dict_pat_v2.to_excel(writer, sheet_name='Patient', index=False)\n",
    "    df_dict_enc.to_excel(writer, sheet_name='Encounter', index=False)\n",
    "print(f'Patient-level dictionary updated with {df_dict_pat_v2.shape[0]} variables.')\n",
    "\n",
    "# The data dictionary should contain 1 variable (PatientDurableKey) less than the data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
