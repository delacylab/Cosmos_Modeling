{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8af71d80-bcc3-41e9-ad79-87f80bef4469",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################################\n",
    "# Overview: This script cleans the extracted encounter-level data mart.\n",
    "############################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7cedbe5-1e71-4b13-95f0-557c6f0dac48",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "########################################################################################################################\n",
    "# Import packages\n",
    "########################################################################################################################\n",
    "import datetime\n",
    "import gc\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import warnings\n",
    "from ast import literal_eval\n",
    "from pyarrow.parquet import ParquetFile\n",
    "warnings.filterwarnings('ignore', category=pd.errors.SettingWithCopyWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "613bc638-c5b5-43c8-b363-315092356500",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################################################\n",
    "# USER_SPECIFIC SETTING\n",
    "# DATA_IN_DIR_PATH: Path of the input directory of the encounter-level dataset \n",
    "# (created in C01_Data_Transfer.ipynb)\n",
    "# DATA_OUT_DIR_PATH: Path of the output directory of the encounter-level dataset \n",
    "# (created in C01_Data_Transfer.ipynb)\n",
    "# DICT_IN_FILE_PATH: Path of the input data dictionary file\n",
    "# (created in C04_Clean_Encounter_Variables.ipynb)\n",
    "# DICT_OUT_FILE_PATH: Path of the output data dictionary file\n",
    "########################################################################################################################\n",
    "DATA_IN_DIR_PATH: str = '../00_Data/00_Raw_Data/'\n",
    "DATA_OUT_DIR_PATH: str = '../00_Data/01_Cleaned_Data/'\n",
    "DICT_IN_FILE_PATH: str = '../00_Data/99_Dictionary/Dictionary_v3.xlsx'\n",
    "DICT_OUT_FILE_PATH: str = '../00_Data/99_Dictionary/Dictionary_v4.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd2c0d5-ec6a-4195-bb20-22c871047eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################################################\n",
    "# Load the data dictionary\n",
    "########################################################################################################################\n",
    "df_dict_pat: pd.DataFrame = pd.read_excel(DICT_IN_FILE_PATH, sheet_name='Patient')\n",
    "df_dict_enc: pd.DataFrame = pd.read_excel(DICT_IN_FILE_PATH, sheet_name='Encounter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938f35b6-084f-4dea-925b-17b4bf4567e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################################################\n",
    "# Load the header of the encounter-level dataset\n",
    "########################################################################################################################\n",
    "enc_data_path: str = os.path.join(DATA_IN_DIR_PATH, 'Encounter_full.parquet')\n",
    "pf: ParquetFile = ParquetFile(enc_data_path)\n",
    "first_row: pa.lib.RecordBatch = next(pf.iter_batches(batch_size=1))\n",
    "header: list[str] = pa.Table.from_batches([first_row]).to_pandas().columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70518311-1781-4304-8d7f-fd6ff557577b",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################################################\n",
    "# Initiate a single-column pandas.DataFrame containing the first two columns of the encounter-level dataset\n",
    "# (i.e., 'EncounterKey' and 'PatientDurableKey')\n",
    "# Create an extra copy of df_dict_pat for modification\n",
    "########################################################################################################################\n",
    "df_out: pd.DataFrame = pd.DataFrame({header[0]: pd.read_parquet(enc_data_path, columns=[header[0]]).iloc[:, 0],\n",
    "                                     header[1]: pd.read_parquet(enc_data_path, columns=[header[1]]).iloc[:, 0]})\n",
    "N: int = df_out.shape[0]    \n",
    "df_dict_enc_v2: pd.DataFrame = pd.DataFrame(None, columns=df_dict_enc.columns)\n",
    "df_dict_enc_v2.insert(2, 'Sampled_Percentage', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50882642-c2f0-4c9c-8d68-6e581427c09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################################################\n",
    "# Part A. Encode and extract data of date & continuous variables\n",
    "########################################################################################################################\n",
    "for row_idx, row in df_dict_enc[df_dict_enc['Variable_Type'].isin(['datetime.date',\n",
    "                                                                  'Date as float',\n",
    "                                                                  'Date as integer',\n",
    "                                                                  'Year as float',\n",
    "                                                                  'Continuous'])].iterrows():\n",
    "\n",
    "    var_name: str = row['Variable_Name']\n",
    "    var_type: str = row['Variable_Type']\n",
    "    remark: str = row['Remark']\n",
    "    log_head: str = f'[{row_idx}. {var_name}]'\n",
    "\n",
    "    ####################################################################################################################\n",
    "    # A1. Load the uncleaned single-column data\n",
    "    ####################################################################################################################\n",
    "    df_cur: pd.DataFrame = pd.read_parquet(enc_data_path, columns=[var_name])\n",
    "\n",
    "    ####################################################################################################################\n",
    "    # A2. Extract data\n",
    "    ####################################################################################################################\n",
    "    # Case 1. Date variables in datetime.date format\n",
    "    if var_type == 'datetime.date':\n",
    "        print(f'{log_head}datetime.date -> Date')\n",
    "        df_cur[var_name] = pd.to_datetime(df_cur[var_name])\n",
    "        new_var_type: str = 'Date'\n",
    "\n",
    "    # Case 2. Date variables in float format\n",
    "    elif var_type in ['Date as float', 'Date as integer']:\n",
    "        print(f'{log_head}Date as integer/float -> Date')\n",
    "        df_cur[var_name] = df_cur[var_name].apply(lambda x: str(int(x)) if pd.notna(x) else None)\n",
    "        df_cur[var_name] = pd.to_datetime(df_cur[var_name], format='%Y%m%d', errors='coerce')\n",
    "        new_var_type: str = 'Date'\n",
    "\n",
    "    # Case 3. Year variables in float format\n",
    "    elif var_type in ['Year as float']:\n",
    "        print(f'{log_head}Year as float -> Year')\n",
    "        df_cur[var_name] = df_cur[var_name].apply(lambda x: str(int(x)) if pd.notna(x) else None)\n",
    "        df_cur[var_name] = pd.to_datetime(df_cur[var_name], format='%Y', errors='coerce')\n",
    "        new_var_type: str = 'Year'\n",
    "\n",
    "    # Case 4. Continuous variables\n",
    "    else:\n",
    "        print(f'{log_head}Continuous (as is)')\n",
    "        new_var_type: str = 'Continuous'\n",
    "\n",
    "    df_out[var_name] = df_cur[var_name]\n",
    "\n",
    "    ####################################################################################################################\n",
    "    # A3. Update dictionary\n",
    "    ####################################################################################################################\n",
    "    sampled_ratio: int = int(round(df_cur[var_name].notna().sum() / N, 2) * 100)\n",
    "    record_cur: pd.DataFrame = pd.DataFrame({'Variable_Name': [var_name],\n",
    "                                             'Sample_Size': int(df_cur[var_name].notna().sum()),\n",
    "                                             'Sampled_Percentage': [sampled_ratio],\n",
    "                                             'Encoded_Values': [np.nan],\n",
    "                                             'Variable_Type': [new_var_type],\n",
    "                                             'Remark': [remark]})\n",
    "    df_dict_enc_v2 = pd.concat([df_dict_enc_v2, record_cur], ignore_index=True)\n",
    "    del df_cur\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6276ca9-021c-4f0e-8732-e546f819dce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################################################\n",
    "# Part B. Encode all binary / ordinal variables (no nominal variables found)\n",
    "########################################################################################################################\n",
    "df_dict_enc_sub: pd.DataFrame = df_dict_enc[df_dict_enc['Variable_Type'].isin(['Binary', 'Ordinal'])]\n",
    "df_out_cat: pd.DataFrame = pd.DataFrame(None)        # Create empty pandas.DataFrame for the data and dictionary of\n",
    "df_dict_enc_cat: pd.DataFrame = pd.DataFrame(None)   # the categorical variables\n",
    "\n",
    "for row_idx, row in df_dict_enc_sub.iterrows():\n",
    "    var_name: str = row['Variable_Name']\n",
    "    var_type: str = row['Variable_Type']\n",
    "    encoder: dict[str, int] = literal_eval(row['Encoded_Values'])\n",
    "    remark: str = row['Remark']\n",
    "    log_head: str = f'[{row_idx}. {var_name}]'\n",
    "\n",
    "    ####################################################################################################################\n",
    "    # B1. Load the uncleaned single-column data\n",
    "    ####################################################################################################################\n",
    "    df_cur: pd.DataFrame = pd.read_parquet(enc_data_path, columns=[var_name])\n",
    "\n",
    "    ####################################################################################################################\n",
    "    # B2. Identify the codes for missingness\n",
    "    ####################################################################################################################\n",
    "    missing_encoder: dict[str, int] = {k: v for k, v in encoder.items() if v is not None and v < 0}\n",
    "    non_missing_encoder: dict[str, int] = {k: v for k, v in encoder.items() if v is not None and v >= 0}\n",
    "    missing_decoder: dict[int, str] = {v: k for k, v in missing_encoder.items()}\n",
    "    non_missing_decoder: dict[int, str] = {v: k for k, v in non_missing_encoder.items()}\n",
    "    assert len(missing_decoder) == 0   # We do not have any missing values encoded in the encounter-level dataset\n",
    "\n",
    "    ####################################################################################################################\n",
    "    # B3. Apply the encoder to the data\n",
    "    ####################################################################################################################\n",
    "    df_cur[var_name].replace(encoder, inplace=True)\n",
    "\n",
    "    #####################################################################################################################\n",
    "    # B4. Handle non-ordinal variables first\n",
    "    #####################################################################################################################\n",
    "    if var_type == 'Binary':\n",
    "        assert len(non_missing_encoder) == 2\n",
    "        assert set(non_missing_encoder.values()) == {0, 1}, non_missing_encoder.values()\n",
    "    \n",
    "        # 4.1 Encode only the positive value for binary variables, and all values for nominal variables\n",
    "        for k, v in non_missing_decoder.items():\n",
    "            if var_type == 'Binary' and k == 0:\n",
    "                continue\n",
    "    \n",
    "            new_var_name: str = f'{var_name}^{k}={v}'\n",
    "            df_out_cat[new_var_name] = df_cur[var_name].apply(\n",
    "                lambda x: np.nan if pd.isna(x) or x < 0\n",
    "                else int(x == k)\n",
    "            ).astype('Int32')   # Cleaned data\n",
    "    \n",
    "            sample_size: int = df_out_cat[new_var_name].notna().sum()\n",
    "            sampled_ratio: int = int(round(sample_size / N, 2) * 100)\n",
    "            record_cur: pd.DataFrame = pd.DataFrame({'Variable_Name': [new_var_name],\n",
    "                                                     'Sample_Size': [sample_size],\n",
    "                                                     'Sampled_Percentage': [sampled_ratio],\n",
    "                                                     'Encoded_Values': [{0: 'No', 1: 'Yes'}],\n",
    "                                                     'Variable_Type': ['Binary'],\n",
    "                                                     'Remark': [remark]})\n",
    "    \n",
    "            df_dict_enc_cat = pd.concat([df_dict_enc_cat, record_cur], ignore_index=True)   # Cleaned dictionary\n",
    "            print(f'{log_head}{(k, v)} encoded.')\n",
    "    \n",
    "    ########################################################################################################################\n",
    "    # B5. Handle nominal encoding\n",
    "    ########################################################################################################################\n",
    "    else:\n",
    "        assert len(non_missing_encoder) > 2\n",
    "\n",
    "        # 5.1 Encode only the non-negative values\n",
    "        df_out_cat[var_name] = df_cur[var_name].apply(\n",
    "            lambda x: np.nan if pd.isna(x) or x < 0 else x\n",
    "        ).astype('Int32')\n",
    "    \n",
    "        sample_size: int = df_out_cat[var_name].notna().sum()\n",
    "        sampled_ratio: int = int(round(sample_size / N, 2) * 100)\n",
    "        record_cur: pd.DataFrame = pd.DataFrame({'Variable_Name': [var_name],\n",
    "                                                 'Sample_Size': [sample_size],\n",
    "                                                 'Sampled_Percentage': [sampled_ratio],\n",
    "                                                 'Encoded_Values': [non_missing_decoder],\n",
    "                                                 'Variable_Type': ['Ordinal'],\n",
    "                                                 'Remark': [remark]})\n",
    "    \n",
    "        df_dict_enc_cat = pd.concat([df_dict_enc_cat, record_cur], ignore_index=True)   # Cleaned dictionary\n",
    "        print(f'{log_head}Encoded.')\n",
    "    del df_cur\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d87160-e1fe-42db-a921-932cc872efda",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################################################\n",
    "# Part C. Handle the ICD-10 encoding of OutpatPrimaryDx, OutpatNonPrimaryDx, EDPrimDx\n",
    "########################################################################################################################\n",
    "\n",
    "########################################################################################################################\n",
    "# C1. Extract the three columns of data from the encounter-level dataset\n",
    "########################################################################################################################\n",
    "icd_cols: list[str] = ['OutpatPrimaryDx', 'OutpatNonPrimaryDx', 'EDPrimDx']\n",
    "df: pd.DataFrame = pd.read_parquet(enc_data_path, columns=icd_cols)\n",
    "\n",
    "########################################################################################################################\n",
    "# C2. Turn the values of each column into a list of ICD codes\n",
    "########################################################################################################################\n",
    "unique_codes: list[str] = []\n",
    "for col in df:\n",
    "    df[col] = df[col].apply(lambda x: [] if pd.isna(x) else x.split(','))\n",
    "    unique_codes += [icd_code for code_list in df[col].values for icd_code in code_list]\n",
    "\n",
    "unique_codes = sorted(set(unique_codes))\n",
    "print(f'{len(unique_codes)} unique ICD codes found.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2827e3b7-a1f5-4af9-b049-10e53d260b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################################################\n",
    "# C3. Write a function to parse an ICD code into its chapter-level code\n",
    "# See https://icd.who.int/browse10/2019/en and https://icd10data.com/ICD10CM/Codes\n",
    "########################################################################################################################\n",
    "\n",
    "# Define the 22 chapters\n",
    "chapter_dict: dict[int, list[str]] = {\n",
    "    1:  [f'{char}{str(i).zfill(2)}' for char in ['A', 'B'] for i in range(100)],\n",
    "    2:  [f'C{str(i).zfill(2)}' for i in range(98)] + [f'D{str(i).zfill(2)}' for i in range(50)] + ['C4A', 'C7A', 'C7B', 'D3A'],\n",
    "    3:  [f'D{str(i).zfill(2)}' for i in range(50, 90)],\n",
    "    4:  [f'E{str(i).zfill(2)}' for i in range(100)],\n",
    "    5:  [f'F{str(i).zfill(2)}' for i in range(100)],\n",
    "    6:  [f'G{str(i).zfill(2)}' for i in range(100)],\n",
    "    7:  [f'H{str(i).zfill(2)}' for i in range(60)],\n",
    "    8:  [f'H{str(i).zfill(2)}' for i in range(60, 96)],\n",
    "    9:  [f'I{str(i).zfill(2)}' for i in range(100)] + ['I1A', 'I5A'],\n",
    "    10: [f'J{str(i).zfill(2)}' for i in range(100)],\n",
    "    11: [f'K{str(i).zfill(2)}' for i in range(96)],\n",
    "    12: [f'L{str(i).zfill(2)}' for i in range(100)],\n",
    "    13: [f'M{str(i).zfill(2)}' for i in range(100)] + ['M1A'],\n",
    "    14: [f'N{str(i).zfill(2)}' for i in range(100)],\n",
    "    15: [f'O{str(i).zfill(2)}' for i in range(100)] + ['O9A'],\n",
    "    16: [f'P{str(i).zfill(2)}' for i in range(97)],\n",
    "    17: [f'Q{str(i).zfill(2)}' for i in range(100)],\n",
    "    18: [f'R{str(i).zfill(2)}' for i in range(100)],\n",
    "    19: [f'S{str(i).zfill(2)}' for i in range(100)] + [f'T{str(i).zfill(2)}' for i in range(99)],\n",
    "    20: [f'{char}{str(i).zfill(2)}' for char in ['V', 'W', 'X', 'Y'] for i in range(100)],\n",
    "    21: [f'Z{str(i).zfill(2)}' for i in range(100)] + ['Z3A'],\n",
    "    22: [f'U{str(i).zfill(2)}' for i in range(86)]\n",
    "}\n",
    "\n",
    "chapter_dict = {k: set(v) for k, v in chapter_dict.items()}  # Set-operation is much faster than list-operation in Python\n",
    "\n",
    "def icd_chapter(icd_code):\n",
    "    parent_code = icd_code.split('.')[0] if '.' in icd_code else icd_code\n",
    "    for k, v in chapter_dict.items():\n",
    "        if parent_code in v:\n",
    "            return k\n",
    "    return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1df6909-3d23-4ff8-930d-5c3adf4be8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################################################\n",
    "# C4. Create a copy of df and apply the function above from df to the new copy\n",
    "########################################################################################################################\n",
    "df_c: pd.DataFrame = pd.DataFrame(None)\n",
    "for col in icd_cols:\n",
    "    df_c[col] = df[col].apply(lambda x: [icd_chapter(y) for y in x if not y.startswith('IMO')])\n",
    "    print(f'Finished encoding ICD chapter codes for {col}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049e7eee-b3d0-49c4-8e6c-11a27d45669b",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################################################\n",
    "# C5. One-hot encoding\n",
    "########################################################################################################################\n",
    "for col in icd_cols:\n",
    "    for ch_idx in range(1, 23, 1):\n",
    "        new_var_name: str = f'{col}^ch{ch_idx}'\n",
    "        df_c[new_var_name] = df_c[col].apply(\n",
    "            lambda x: np.nan if len(x) == 0 else int(ch_idx in x)\n",
    "        ).astype('Int32')\n",
    "        print(f'Finished encoding chapter {ch_idx} for {col}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46adf3c-fa47-4bb5-9692-32d7b7501af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################################################\n",
    "# C6. Concatenate the data and update the data dictionary\n",
    "########################################################################################################################\n",
    "df_dict_enc_v2 = pd.concat([df_dict_enc_v2, df_dict_enc_cat], axis=0)\n",
    "df_out = pd.concat([df_out, df_out_cat], axis=1)\n",
    "\n",
    "df_c.drop(columns=icd_cols, inplace=True)\n",
    "for col in df_c.columns:\n",
    "    sample_size: int = df_c[col].notna().sum()\n",
    "    sampled_ratio: int = int(round(sample_size / N, 2) * 100)\n",
    "    record_cur: pd.DataFrame = pd.DataFrame({'Variable_Name': [col],\n",
    "                                             'Sample_Size': [sample_size],\n",
    "                                             'Sampled_Percentage': [sampled_ratio],\n",
    "                                             'Encoded_Values': [{0: 'No', 1: 'Yes'}],\n",
    "                                             'Variable_Type': ['Binary'],\n",
    "                                             'Remark': [np.nan]})\n",
    "    df_dict_enc_v2 = pd.concat([df_dict_enc_v2, record_cur], ignore_index=True)  # Cleaned dictionary\n",
    "df_out = pd.concat([df_out, df_c], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e21f69-b930-4e60-a419-0dd7ec1b95ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################################################\n",
    "# Part D. Concatenate the data sets and dictionaries respectively, and save them\n",
    "########################################################################################################################\n",
    "os.makedirs(DATA_OUT_DIR_PATH, exist_ok=True)\n",
    "data_file_path: str = os.path.join(DATA_OUT_DIR_PATH, 'Encounter_full_v1.parquet')\n",
    "df_out.to_parquet(data_file_path)\n",
    "print(f'Cleaned data (v1) saved with dimension={df_out.shape}')\n",
    "\n",
    "with pd.ExcelWriter(DICT_OUT_FILE_PATH) as writer:\n",
    "    df_dict_pat.to_excel(writer, sheet_name='Patient', index=False)\n",
    "    df_dict_enc_v2.to_excel(writer, sheet_name='Encounter', index=False)\n",
    "print(f'Encounter-level dictionary updated with {df_dict_enc_v2.shape[0]} variables.')\n",
    "\n",
    "# The data dictionary should contain 2 variables less than the data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
