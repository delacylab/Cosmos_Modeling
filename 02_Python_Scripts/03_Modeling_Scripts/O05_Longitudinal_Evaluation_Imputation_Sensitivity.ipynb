{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a824fd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################################################\n",
    "# This script organizes the modeling performance results across point prediction models into a single spreadsheet\n",
    "########################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01e3b310",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################################################\n",
    "# Import packages\n",
    "########################################################################################################################\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from _Helper_Scripts.binary_metrics import binary_metrics, flagged_at_top_k_ppv,  nb_weight_from_pt, threshold_at_specificity_k \n",
    "from itertools import product\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6051cef-70eb-40c0-abc8-a704ba23a806",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################################################\n",
    "# USER_SPECIFIC SETTING\n",
    "# C_LIST: A list of different numbers of feature encounteres to be included\n",
    "# D_LIST: A list of different maximum widths of the look-back window in days\n",
    "# ABLATION: Boolean. False for pre-ablation modeling and True for post-ablation modeling\n",
    "# IMPUTE_LIST: A list of strings representing the imputation methods adopted\n",
    "# CSL: Boolean. False for standard learning and True for cost-sensitive learning\n",
    "# DECIMALS: A integer representing the number of decimal points to display for performance statistics\n",
    "# PT: A float representing the policy decision threshold for calculating once-off (standardized) net benefit\n",
    "# IN_DIR: The input path of the directories storing the modeling results \n",
    "# (e.g., the directory with the subdirectory RiskPath_Results/) \n",
    "# OUT_DIR: The output path of the directory storing the overall performance statistics\n",
    "########################################################################################################################\n",
    "C_LIST: list[int] = [2, 3, 4]\n",
    "D_LIST: list[int] = [60, 120, 180]\n",
    "ABLATION: bool = False\n",
    "IMPUTE_LIST: list[str] = ['Zero', 'Mean', 'Median']\n",
    "CSL: bool = False\n",
    "DECIMALS: int = 2\n",
    "PT: float = 1 / 11\n",
    "IN_DIR: str = ''\n",
    "OUT_DIR: str = '_Final_Results/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7002be",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################################\n",
    "# Extract probability estimates\n",
    "############################################################################################################\n",
    "files_needed: dict[tuple[int, int, str], str] = {}\n",
    "base_dir: str = 'RiskPath_Results_Ablated' if ABLATION else 'RiskPath_Results/'\n",
    "base_dir = os.path.join(IN_DIR, base_dir, 'Predicted_Probabilities/')\n",
    "for C, D in product(C_LIST, D_LIST):\n",
    "    for impute in IMPUTE_LIST:\n",
    "        file_path: str = f'{base_dir}{C}_encounters_{D}_days_{impute}'\n",
    "        if ABLATION:\n",
    "            file_path += '_Ablated'\n",
    "        file_path += '.csv'\n",
    "        if CSL:\n",
    "            file_path = file_path.replace('.csv', '_CSL.csv')\n",
    "        files_needed[(C, D, impute)] = file_path\n",
    "for k, v in files_needed.items():\n",
    "    assert os.path.exists(v)\n",
    "    # print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "61ff2570",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################################################\n",
    "# Specify the output path of the CSV file\n",
    "########################################################################################################################\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "suffix_1: str = '_POST' if ABLATION else '_PRE'\n",
    "suffix_2: str = '_CSL' if CSL else ''\n",
    "suffix: str = suffix_1 + suffix_2\n",
    "out_file_name: str = os.path.join(OUT_DIR, f'Longitudinal_Performance_Imputation_Sensitivity{suffix}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e1bd177",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################################################\n",
    "# Create a dictionary to store output pandas.DataFrames\n",
    "########################################################################################################################\n",
    "out_dict_list: list[dict] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8536f0-bd65-49b7-bd75-6f9c8f34fec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################################\n",
    "# Load the probability estimates files\n",
    "############################################################################################################\n",
    "for dict_key, file_path in files_needed.items():\n",
    "    dict_key_str: str = f'{dict_key[0]}_{dict_key[1]}_{dict_key[2]}'\n",
    "    df_cur: pd.DataFrame = pd.read_csv(file_path)\n",
    "    \n",
    "    ########################################################################################################\n",
    "    # Extract the true labels and estimated probabilities\n",
    "    ########################################################################################################\n",
    "    y_test = df_cur['y_test'].to_numpy()\n",
    "    y_prob = df_cur['y_prob'].to_numpy()\n",
    "\n",
    "    ########################################################################################################\n",
    "    # Define the selection cutoff for capacity-aligned results\n",
    "    ########################################################################################################\n",
    "    flag_1 = flagged_at_top_k_ppv(y_prob, k=1)\n",
    "    flag_2 = flagged_at_top_k_ppv(y_prob, k=2)\n",
    "    flag_5 = flagged_at_top_k_ppv(y_prob, k=5)\n",
    "    spec_99 = threshold_at_specificity_k(y_test, y_prob, k=99)\n",
    "    spec_95 = threshold_at_specificity_k(y_test, y_prob, k=95)\n",
    "    spec_90 = threshold_at_specificity_k(y_test, y_prob, k=90)\n",
    "    \n",
    "    ########################################################################################################\n",
    "    # Compute the net benefit weight\n",
    "    ########################################################################################################\n",
    "    nbw = nb_weight_from_pt(PT)    # nbw = p_t / (1 - p_t)\n",
    "    \n",
    "    ########################################################################################################\n",
    "    # Obtain the lists of needed statistics\n",
    "    ########################################################################################################\n",
    "    default_stat = binary_metrics(y_true=y_test, y_prob=y_prob, y_pred_override=None, threshold=0.5, nb_weight=nbw, decimals=DECIMALS)\n",
    "    top_1_stat = binary_metrics(y_true=y_test, y_prob=y_prob, y_pred_override=flag_1, threshold=0.5, nb_weight=nbw, decimals=DECIMALS)\n",
    "    top_2_stat = binary_metrics(y_true=y_test, y_prob=y_prob, y_pred_override=flag_2, threshold=0.5, nb_weight=nbw, decimals=DECIMALS)\n",
    "    top_5_stat = binary_metrics(y_true=y_test, y_prob=y_prob, y_pred_override=flag_5, threshold=0.5, nb_weight=nbw, decimals=DECIMALS)\n",
    "    spec_99_stat = binary_metrics(y_true=y_test, y_prob=y_prob, y_pred_override=None, threshold=spec_99, nb_weight=nbw, decimals=DECIMALS)\n",
    "    spec_95_stat = binary_metrics(y_true=y_test, y_prob=y_prob, y_pred_override=None, threshold=spec_95, nb_weight=nbw, decimals=DECIMALS)\n",
    "    spec_90_stat = binary_metrics(y_true=y_test, y_prob=y_prob, y_pred_override=None, threshold=spec_90, nb_weight=nbw, decimals=DECIMALS)\n",
    "\n",
    "    ########################################################################################################\n",
    "    # Create a dictionary for the current set of performance statistics\n",
    "    ########################################################################################################\n",
    "    results_cur: dict[str, float] = {}\n",
    "    \n",
    "    ########################################################################################################\n",
    "    # Organize the statistics\n",
    "    ########################################################################################################\n",
    "    stat_dict: dict[str, list] = {'': default_stat,\n",
    "                                  '@top1%': top_1_stat,\n",
    "                                  '@top2%': top_2_stat,\n",
    "                                  '@top5%': top_5_stat,\n",
    "                                  '@99Spec': spec_99_stat,\n",
    "                                  '@95Spec': spec_95_stat,\n",
    "                                  '@90Spec': spec_90_stat}\n",
    "    for k, v in stat_dict.items():\n",
    "        results_cur |= {f'{i}{k}': j for i, j in v.items() if not i.endswith('_LIST')}\n",
    "    results_cur = {k: results_cur[k] for k in sorted(results_cur.keys())}\n",
    "    results_cur = {'Setting': dict_key_str} | results_cur\n",
    "    out_dict_list.append(results_cur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "196aba48",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################################################\n",
    "# Export out_dict_list as a CSV file\n",
    "########################################################################################################################\n",
    "df_out: pd.DataFrame = pd.DataFrame.from_records(out_dict_list)\n",
    "df_out = df_out.set_index('Setting').T\n",
    "df_out.to_csv(out_file_name, index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
