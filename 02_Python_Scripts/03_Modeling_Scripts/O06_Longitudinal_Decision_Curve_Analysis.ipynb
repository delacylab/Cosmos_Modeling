{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01e3b310",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################################################\n",
    "# This script visualizes the decision curve analysis for longitudinal prediction models\n",
    "# Remark: This script adopts the visual configuration of a 3x3 panels. Please revise it accordingly if you adopt a \n",
    "# different setting. \n",
    "########################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063effdf-0cc6-41db-9826-e347f2a17794",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################################################\n",
    "# Import packages\n",
    "########################################################################################################################\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from itertools import product\n",
    "mpl.rcParams[\"font.family\"] = \"sans-serif\"\n",
    "mpl.rcParams[\"font.sans-serif\"] = [\"Century Gothic\"]\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec26a9ac-c7b8-4a38-8209-e5c3ee90a359",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################################################\n",
    "# USER_SPECIFIC SETTING\n",
    "# C_LIST: A list of different numbers of feature encounteres to be included\n",
    "# D_LIST: A list of different maximum widths of the look-back window in days\n",
    "# ABLATION: Boolean. False for pre-ablation modeling and True for post-ablation modeling\n",
    "# IMPUTE: A string representing the imputation method adopted (in 'Zero', 'Mean', and 'Median')\n",
    "# CSL: Boolean. False for standard learning and True for cost-sensitive learning\n",
    "# IN_DIR: The input path of the directories storing the modeling results \n",
    "# (e.g., the directory with the subdirectory RiskPath_Results/) \n",
    "# OUT_DIR: The output path of the directory storing the overall performance statistics\n",
    "########################################################################################################################\n",
    "C_LIST: list[int] = [2, 3, 4]\n",
    "D_LIST: list[int] = [60, 120, 180]\n",
    "ABLATION: bool = False\n",
    "IMPUTE: str = 'Zero'\n",
    "CSL: bool = False\n",
    "IN_DIR: str = ''\n",
    "OUT_DIR: str = '_Final_Results/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cab4d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################################################\n",
    "# Specify the directories to extract probability estimates\n",
    "########################################################################################################################\n",
    "ablate_str: str = '_Ablated' if ABLATION else ''\n",
    "csl_str: str = '_CSL' if CSL else ''\n",
    "files_needed: dict[tuple[int, int], str] = {}\n",
    "for C, D in product(C_LIST, D_LIST):\n",
    "    dir_path: str = os.path.join(IN_DIR, f'RiskPath_Results{ablate_str}/Predicted_Probabilities/')\n",
    "    file_path: str = dir_path + f'{C}_encounters_{D}_days_{IMPUTE}{ablate_str}{csl_str}.csv'    \n",
    "    files_needed[(C, D)] = file_path\n",
    "for k, v in files_needed.items():\n",
    "    assert os.path.exists(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f426ae26",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################################################\n",
    "# Define a function to compute standardized net benefit (sNB)\n",
    "########################################################################################################################\n",
    "def nb(y_true_, y_prob_, pt, standard=True):\n",
    "    y_pred_ = (y_prob_ >= pt).astype(int)\n",
    "    TP = np.sum((y_pred_ == 1) & (y_true_ == 1))\n",
    "    FP = np.sum((y_pred_ == 1) & (y_true_ == 0))\n",
    "    n = len(y_true_)\n",
    "    nb = (TP / n) - (FP / n) * (pt / (1 - pt))\n",
    "    snb = nb / np.mean(y_true_)\n",
    "    return snb if standard else nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e172ba8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################################################\n",
    "# Define other relevant functions to compute sNB (from counts and treat all)\n",
    "########################################################################################################################\n",
    "def nb_from_counts(tp, fp, n, pt, prevalence, standard=True):\n",
    "    nb = (tp / n) - (fp / n) * (pt / (1 - pt))\n",
    "    return nb / prevalence if standard else nb\n",
    "\n",
    "def compute_treat_all_nb(y_true, pts, standard=True):\n",
    "    n = len(y_true)\n",
    "    prev = np.mean(y_true)\n",
    "    tp = np.sum(y_true == 1)\n",
    "    fp = np.sum(y_true == 0)\n",
    "    return [nb_from_counts(tp, fp, n, pt, prev, standard=standard) for pt in pts]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b24270e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################################################\n",
    "# Create dictionaries to save true labels, probabilities, and sNB values\n",
    "########################################################################################################################\n",
    "true_dict: dict = {}\n",
    "prob_dict: dict = {}\n",
    "nb_dict: dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2b0e7ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################################################\n",
    "# Define the policy thresholds for the computation of sNB\n",
    "########################################################################################################################\n",
    "POLICY_PROBS = np.array([i / 1000 for i in range(1, 1000)], dtype=float)\n",
    "assert np.all((POLICY_PROBS > 0) & (POLICY_PROBS < 1)), 'Each element in POLICY_PROBS must be strictly within (0, 1)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b2dcd8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################################################\n",
    "# Load the probability estimates files\n",
    "########################################################################################################################\n",
    "for config, file_path in files_needed.items():\n",
    "    df_cur: pd.DataFrame = pd.read_csv(file_path)\n",
    "\n",
    "    ####################################################################################################################\n",
    "    # Extract the true labels and estimated probabilities\n",
    "    # Compute and store the standardized net benefit (sNB) for each decision threshold in POLICY_PROBS\n",
    "    ####################################################################################################################\n",
    "    y_test = df_cur['y_test'].to_numpy()\n",
    "    y_prob = df_cur['y_prob'].to_numpy()\n",
    "\n",
    "    true_dict[config] = y_test\n",
    "    prob_dict[config] = y_prob\n",
    "    nb_dict[config] = [nb(y_test, y_prob, pt, standard=True) for pt in POLICY_PROBS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f0379e",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################################################\n",
    "# Create the 3x3 subplot figure\n",
    "########################################################################################################################\n",
    "configs = sorted(files_needed.keys())\n",
    "fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(15, 7))\n",
    "axes = axes.ravel()\n",
    "for i, config in enumerate(configs):\n",
    "    ax = axes[i]\n",
    "    y_true = true_dict[config]\n",
    "    nb_vals = np.asarray(nb_dict[config], dtype=float)\n",
    "    ax.plot(POLICY_PROBS, nb_vals, label=f'RiskPath', linewidth=3, color='tab:blue')\n",
    "    ax.plot(POLICY_PROBS, compute_treat_all_nb(y_true, POLICY_PROBS, standard=True), linestyle='--', label='Treat all', color='tab:brown', linewidth=3)\n",
    "    ax.axhline(0.0, linestyle='-', linewidth=3, label='Treat none', color='black')\n",
    "    ax.grid(alpha=0.5)\n",
    "    ax.set_ylim(-0.1, 1.05)\n",
    "    ax.set_xlim(0, 0.8)      # Revise if needed\n",
    "    ax.tick_params(axis='both', which='major', labelsize=13)\n",
    "\n",
    "for j in range(len(configs), len(axes)):\n",
    "    axes[j].axis('off')\n",
    "\n",
    "col_labels = D_LIST\n",
    "for col, d in enumerate(col_labels):\n",
    "    fig.text(0.2 + col * 0.32, 0.93, f'{d} lookback days',\n",
    "             ha='center', va='bottom', fontsize=20, fontweight='bold')\n",
    "row_labels = C_LIST\n",
    "for row, c in enumerate(row_labels):\n",
    "    fig.text(-0.02, 0.80 - row * 0.29, f'{c} encounters',\n",
    "             ha='left', va='center', fontsize=20, fontweight='bold', rotation=90)\n",
    "\n",
    "fig.supxlabel('Threshold probability (p' + r'$_t$' +')', fontsize=20)\n",
    "fig.supylabel('Standardized net benefit (sNB)', fontsize=20, x=0.01)\n",
    "handles, labels = axes[0].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, \n",
    "           bbox_to_anchor=(0.5, 1.07), ncols=4, loc='upper center', frameon=True, \n",
    "           fontsize=20)         \n",
    "plt.tight_layout(rect=[0, 0, 1, 0.94])\n",
    "out_path = os.path.join(OUT_DIR, f\"DCA_Longitudinal_sNB_{IMPUTE}{ablate_str}{csl_str}.png\")\n",
    "plt.savefig(out_path, dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
