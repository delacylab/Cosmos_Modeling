{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a824fd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################################################\n",
    "# This script identifies the patients to be included in the experiment for different experiment settings.\n",
    "########################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01e3b310",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################################################\n",
    "# Import packages\n",
    "########################################################################################################################\n",
    "import datetime\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from itertools import product\n",
    "pd.set_option('display.float_format', '{:.0f}'.format)\n",
    "warnings.filterwarnings('ignore', category=pd.errors.SettingWithCopyWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b85cc6f-f47a-457e-b875-aaa3a8580936",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################################################\n",
    "# USER-SPECIFIC SETTING\n",
    "# PAT_PATH: Path of the patient-level dataset (created in C07_Date_Adjustment.ipynb)\n",
    "# ENC_PATH: Path of the encounter-level dataset (created in C07_Date_Adjustment.ipynb)\n",
    "# OUT_DIR_PATH: Path of the directory of the output datasets\n",
    "########################################################################################################################\n",
    "PAT_PATH: str = '../00_Data/01_Cleaned_Data/Patient_full_v2.parquet'\n",
    "ENC_PATH: str = '../00_Data/01_Cleaned_Data/Encounter_full_v2.parquet'\n",
    "OUT_DIR_PATH: str = '../00_Data/02_Processed_Data/Targets/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbd6647-4907-40c4-bfaf-df699ce66fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################################################\n",
    "# USER-SPECIFIC SETTING\n",
    "# Cs: Different numbers of feature encounteres to be included\n",
    "# Ds: Different maximum widths of the look-back window in days\n",
    "########################################################################################################################\n",
    "Cs : list[int] = [1, 2, 3, 4]\n",
    "Ds : list[int] = [60, 120, 180]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a657c025-969c-4c76-bd0c-cd2b4b035f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################################################\n",
    "# Define a function to return the target distribution \n",
    "########################################################################################################################\n",
    "def target_dist(df_in: pd.DataFrame, \n",
    "                col: str):\n",
    "    assert col in df_in.columns\n",
    "    v_count: dict[int, int] = df_in[col].value_counts().sort_index().to_dict()\n",
    "    v_count_rate: dict[int, float] = df_in[col].value_counts(normalize=True).sort_index().to_dict()\n",
    "    dist: dict[int, tuple[int, float]] = {k: (v_count[k], f'{round(v_count_rate[k], 3)*100:.1f}%') for k in v_count.keys()}\n",
    "    dist |= {'Total': (df_in.shape[0], '100.0%')}\n",
    "    return f'Distribution of target label ({col}): {dist}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efb00486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "578521 patients identified.\n"
     ]
    }
   ],
   "source": [
    "########################################################################################################################\n",
    "# Load the patient-level dataset\n",
    "########################################################################################################################\n",
    "pat_id_col: str = 'PatientDurableKey'\n",
    "\n",
    "needed_cols: list[str] = [pat_id_col, 'BirthDate']\n",
    "needed_cols += ['Sex^0=Female', 'Sex^1=Male', 'Sex^2=Other']\n",
    "needed_cols += ['GenderIdentity^0=Female', 'GenderIdentity^1=Male',\n",
    "                'GenderIdentity^2=Transgender Male / Female-to-Male',\n",
    "                'GenderIdentity^3=Transgender Female / Male-to-Female',\n",
    "                'GenderIdentity!-1=Choose not to disclose']\n",
    "needed_cols += ['Race^0=American Indian or Alaska Native', 'Race^1=Asian',\n",
    "                'Race^2=Black or African American', 'Race^3=Native Hawaiian or Other Pacific Islander',\n",
    "                'Race^4=Other Race', 'Race^5=White', 'Race^6=Multiple Races']\n",
    "needed_cols += ['Ethnicity^1=Hispanic or Latino']\n",
    "\n",
    "df_y: pd.DataFrame = pd.read_parquet(PAT_PATH, columns=needed_cols)\n",
    "print(f'{df_y.shape[0]} patients identified.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66cb0963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encounter-level dataset loaded with dimension = (4243353, 4)\n"
     ]
    }
   ],
   "source": [
    "########################################################################################################################\n",
    "# Load the encounter-level dataset\n",
    "########################################################################################################################\n",
    "enc_id_col: str = 'EncounterKey'\n",
    "enc_date_col: str = 'EncDate'\n",
    "sa_cur_col: str = 'CurrentSuicideAttempt^1=Y'\n",
    "\n",
    "df_enc: pd.DataFrame = pd.read_parquet(ENC_PATH, columns=[pat_id_col, enc_id_col, enc_date_col, sa_cur_col])\n",
    "df_enc[enc_date_col] = df_enc[enc_date_col].dt.date\n",
    "df_enc.sort_values(by=[pat_id_col, enc_date_col, enc_id_col], ascending=[True, True, True], inplace=True)\n",
    "print(f'Encounter-level dataset loaded with dimension = {df_enc.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4c24fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################################################\n",
    "# Merge the two datasets\n",
    "########################################################################################################################\n",
    "df_enc_gb: pd.DataFrame = df_enc.sort_values([pat_id_col, enc_date_col]).groupby(pat_id_col, as_index=False).agg({enc_id_col: list,\n",
    "                                                                                                                  enc_date_col: list,\n",
    "                                                                                                                  sa_cur_col: list})\n",
    "df_enc_gb = pd.merge(left=df_y[[pat_id_col, 'BirthDate']], right=df_enc_gb, on=pat_id_col, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59aca10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################################################\n",
    "# Display the merged dataset\n",
    "########################################################################################################################\n",
    "df_enc_gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5d8a41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################################################\n",
    "# Description of the subject inclusion criteria\n",
    "########################################################################################################################\n",
    "# Rule 1. Requirement of number of encounters\n",
    "# The patient must have ≥ C+1 encounters (i.e., C feature encounters and 1 outcome encounter).\n",
    "\n",
    "# Rule 2. Proximity of the most recent feature encounter and the outcome encounter\n",
    "# Let last_feat_enc_date be the date of the most recent feature encounter.\n",
    "# Days between outcome and last_feat_enc_date must be in (0, 30].\n",
    "\n",
    "# Rule 3. Width of look-back window\n",
    "# Let first_feat_enc_date be the date of the earliest feature encounter. \n",
    "# Days between outcome and first_feat_enc_date must be ≤ D.\n",
    "\n",
    "# Rule 4. Age requirement\n",
    "# Age at the outcome encounter must be in the range [10, 100].\n",
    "\n",
    "########################################################################################################################\n",
    "# Algorithm\n",
    "########################################################################################################################\n",
    "# Step 1. Given the specified configuration of C and D, loop over all the patients in the cohort.\n",
    "\n",
    "# Step 2. For each patient A, set the patient's last encounter stored in the EHR system as the outcome encounter, and \n",
    "# the preceding C encounters as feature encounters.\n",
    "\n",
    "# Step 3. Check whether Rules 1-4 are satisfied. If yes, include patient A with the corresponding set of encounters.\n",
    "# Otherwise, remove the last encounter of A stored in the EHR system.\n",
    "\n",
    "# Step 4. If patient A was included in Step 3, move on to the next patient. \n",
    "# Otherwise, repeat Step 3 until either A is included or A has ≤ C+1 encounters (violating Rule 1 and thus excluded)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec72ea57",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################################################\n",
    "# Loop over the experiment configurations\n",
    "########################################################################################################################\n",
    "for exp_idx, (C, D) in enumerate(product(Cs, Ds), 1):\n",
    "    log_head: str = f'[{exp_idx}. C={C}; D={D}] '\n",
    "    \n",
    "    if C == 1 and Ds.index(D) > 0:      # When C=1, all D values are the same\n",
    "        continue\n",
    "\n",
    "    ####################################################################################################################\n",
    "    # Create a list to save the patients (and their encounters) to be included\n",
    "    ####################################################################################################################\n",
    "    include_list: list = []\n",
    "\n",
    "    ####################################################################################################################\n",
    "    # Loop over each row in df_enc_gb (one row for each patient)\n",
    "    ####################################################################################################################\n",
    "    for row_idx, row in df_enc_gb.iterrows():\n",
    "        \n",
    "        # R1: With at least C+1 encounters (i.e., C encounters for features, 1 encounter for outcome) \n",
    "        if len(row['EncounterKey']) < C+1:\n",
    "            continue\n",
    "\n",
    "        # Create a mutation copy of row for subsequent modification\n",
    "        row_cur = row.copy(deep=True)\n",
    "\n",
    "        # Start a while-loop to extract a window with C+1 encounters\n",
    "        # When row_cur has less than C+1 encounters, the patient will be excluded.\n",
    "        while len(row_cur['EncounterKey']) >= C+1:  \n",
    "\n",
    "            # (a) Date and key of outcome encounter\n",
    "            outcome_enc_date: datetime.date = row_cur[enc_date_col][-1]  \n",
    "            outcome_enc_key: int = row_cur[enc_id_col][-1]\n",
    "\n",
    "            # (b) Dates and keys of feature encounters \n",
    "            feat_enc_dates: list[datetime.date] = row_cur[enc_date_col][-(C+1):-1] if C > 1 else [row_cur[enc_date_col][-2]]\n",
    "            feat_enc_keys: list[int] = row_cur[enc_id_col][-(C+1):-1] if C > 1 else [row_cur[enc_id_col][-2]]\n",
    "            assert len(feat_enc_keys) == C, (len(feat_enc_keys), C)\n",
    "  \n",
    "            # (c) The latest and earliest dates of feature encounters \n",
    "            last_feat_enc_date: datetime.date = feat_enc_dates[-1]\n",
    "            first_feat_enc_date: datetime.date = feat_enc_dates[0]\n",
    "\n",
    "            # (d) Difference in days compared to the outcome encounter date\n",
    "            last_diff_days: int = (pd.to_datetime(outcome_enc_date) - pd.to_datetime(last_feat_enc_date)).days\n",
    "            first_diff_days: int = (pd.to_datetime(outcome_enc_date) - pd.to_datetime(first_feat_enc_date)).days\n",
    " \n",
    "            # (e) Age at outcome encounter\n",
    "            enc_age: int = int((pd.to_datetime(outcome_enc_date) - pd.to_datetime(row_cur['BirthDate'])).days / 365)\n",
    "\n",
    "            # Define R2-R4\n",
    "            R2: bool = 0 < last_diff_days <= 30\n",
    "            R3: bool = first_diff_days <= D\n",
    "            R4: bool = 10 <= enc_age <= 100\n",
    "\n",
    "            # Check R2-R4\n",
    "            if R2 and R3 and R4:\n",
    "                include_record: dict = {pat_id_col: row_cur[pat_id_col],\n",
    "                                        'OutcomeDate': outcome_enc_date,\n",
    "                                        'OutcomeEncKey': outcome_enc_key,\n",
    "                                        'OutcomeEncAge': enc_age,\n",
    "                                        'OutcomeLabel': row_cur[sa_cur_col][-1],\n",
    "                                        'FeatureEncKeys': feat_enc_keys,\n",
    "                                        'FeatureEncDates': feat_enc_dates}     \n",
    "                include_list.append(include_record)          \n",
    "                break\n",
    "            else:               \n",
    "                for c in [enc_date_col, enc_id_col, sa_cur_col]:            \n",
    "                    row_cur[c] = row_cur[c][:-1]    # Remove the last encounter and repeat (until inclusion or exclusion)\n",
    " \n",
    "    df_include: pd.DataFrame = pd.DataFrame.from_records(include_list)\n",
    "    print(f\"{log_head}{df_include['OutcomeLabel'].value_counts().to_dict()} ... Prevalence = {df_include['OutcomeLabel'].mean()*100:.2f}%\")\n",
    "\n",
    "    # Merge with df_y\n",
    "    df_include = pd.merge(left=df_y, right=df_include, on=pat_id_col, how='right')\n",
    "    \n",
    "    # Export the result\n",
    "    os.makedirs(OUT_DIR_PATH, exist_ok=True)\n",
    "    out_file_path: str = os.path.join(OUT_DIR_PATH, f'{C}_encounters_{D}_days_v1.csv')\n",
    "    df_include.to_csv(out_file_path, index=False)\n",
    "    print(f'{log_head}Dataset saved to {out_file_path}')\n",
    "    print(f'{log_head}Dimension = {df_include.shape}')\n",
    "    print('-'*120)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
